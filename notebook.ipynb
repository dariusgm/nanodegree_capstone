{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "Darius Murawski\n",
    "12.09.2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Definition\n",
    "## Project Overview\n",
    "\n",
    "### Problem Domain\n",
    "\n",
    "Hard drives are used to save data from the operating system and different applications that are running on the server. The average price for a gigabyte is dropping and the demand for more space on the servers is growing. This results in a higher total number of hard drives running. As more drives are present in a data storage system, as more hard drives can fail, leading to data inconsistency and a major fail of the provided services. Since several years, hard drive vendors provide some values of this hard drives that reflect their current state. Based on this values, a broken drive can be identified. For more information on this so called S.M.A.R.T. values, see [wikipedia](https://en.wikipedia.org/wiki/S.M.A.R.T.). \n",
    "\n",
    "### Input Data overview\n",
    "\n",
    "A crash of a hard drive in a private environment is happening very rarely because the amount of total dives is very low. I searched and found a huge dataset provied by [backblaze.com](https://www.backblaze.com/b2/hard-drive-test-data.html). They are running a huge data storage system with several thousend hard drive for their customers. For each quarter, the show their running and failed drives in a csv format for further research. They have a licence for this data, that I like to cite at this place: \n",
    "\n",
    "`You can download and use this data for free for your own purpose, all we ask is three things 1) you cite Backblaze as the source if you use the data, 2) you accept that you are solely responsible for how you use the data, and 3) you do not sell this data to anyone, it is free.`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Fails on a hard drive can be recovered using different techniques like raid settings or mirroring the data in different data centers. But the broken hard drive have to be replaced sooner or later with a new one, to make sure more fails on associated hard drives don’t break the data consistency. For each broken hard drive, somebody have to drive to the storage system, look it up in the storage system and replace it. This procedure have to be done each time one drive fails in the worst case and each time generating maintenance costs for the operating company. \n",
    "\n",
    "This costs can be reduced by replacing more drives than just the broken one by the maintenance people, as they only have to went to the storage system once and not several times. But what drives should they replace? In this Capstone project I want to generate a fail probability for each of the drives running in the storage system. The drives with a predicted fail should be replaced beforehand to reduce the maintenance costs in mid-range for the company operating the storage system.\n",
    "\n",
    "The described problem can be seen as a binary classification problem, where the allowed labels are only 0, for “hard drive is running” and 1 for “hard drive failed”. When generating predictions, 0 represents “hard drive will run further” and 1 for “hard drive will (soon) fail and should be replaced. \n",
    "\n",
    "### Related papers and articles\n",
    "Looking up in papers and articles, this kind of problem is referenced as predictive maintenance (PdM): Before waiting that something breaks, we replace the appropriate part in a regular maintenance to make sure that the entire system is able to continue running as expected.\n",
    "\n",
    "|Authors|Topic / Title|Document|\n",
    "|--|--|--|\n",
    "|Julia Scavicchio|Definition “Predictive Maintenance” (PdM)”|[Link](https://www.hippocmms.com/blog/3-cmms-trends-for-2016-millennials-mobility-and-machine-learning)\n",
    "|Jennifer Ho|Overview of industries, <br>using Algorithms to reduce their machine downtime with further links|[Link](https://www.distrelec.de/current/en/artificial-intelligence/eliminating-machine-downtime-how-ai-is-transforming-maintenance/)\n",
    "|Taylor Short|What type of sensors can be used for predictive maintenance|[Link](https://www.softwareadvice.com/resources/predictive-maintenance-reduce-downtime/)\n",
    "|Gian Antonio Susto,<br> Andrea Schirru,<br> Simone Pampuri,<br> Seán McLoone,<br> Alessandro Beghi|Machine Learning for Predictive Maintenance: <br>A Multiple Classifier Approach|[Link](https://ieeexplore.ieee.org/abstract/document/6879441)\n",
    "|Dr. Miguel A. Sanz Bobi,<br> Maria Cruz García,<br> Javier del Pico-Aznar | SIMAP: Intelligent System for Predictive Maintenance: <br>Application to the health condition monitoring of a windturbine gearbox|[Link](https://www.sciencedirect.com/science/article/pii/S0166361506000534)\n",
    "|Hongfei Li,<br> Dhaivat Parikh,<br> Qing He,<br> Buyue Qian,<br> Zhiguo Li Dongping Fang,<br> Arun Hampapur| Improving rail network velocity: <br>A machine learning approach to predictive maintenance | [Link](https://www.acsu.buffalo.edu/~qinghe/papers/journal/2014%20Railway%20Velocity.pdf)\n",
    "|Eduardo Pinheiro,<br> Wolf-Dietrich Weber,<br> Luiz Andre Barroso - Google| Failure Trends in a Large Disk Drive Population| [Link](http://static.googleusercontent.com/media/research.google.com/en/us/archive/disk_failures.pdf) or [Link](https://ai.google/research/pubs/pub32774)\n",
    "|Various|General Introduction into S.M.A.R.T.|[Link](https://en.wikipedia.org/wiki/S.M.A.R.T.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Statement\n",
    "\n",
    "I want to train a model that returns a \"1\", given by the provided features, that returns a prediction for a hard drive to fail. Drives with this value should be replaced by the maintenance team before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "The data is highly unbalanced. That results in using the F Beta Score to measure the performance of the model. I will not use the accuracy as metric as the data is very unbalanced. See [accuracy paradox](https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "For each day and each drive an entry is generated in a quarter file that is than later on compressed and made available to the public. Failed drives are also included in this dataset and on the next day removed from the list. The dataset contains of the following columns (see: [backblaze.com](https://www.backblaze.com/b2/hard-drive-test-data.html)):\n",
    "\n",
    "* Date – The date of the file in yyyy-mm-dd format.\n",
    "* Serial Number – The manufacturer-assigned serial number of the drive.\n",
    "* Model – The manufacturer-assigned model number of the drive.\n",
    "* Capacity – The drive capacity in bytes.\n",
    "* Failure – Contains a “0” if the drive is OK. Contains a “1” if this is the last day the drive was operational before failing.\n",
    "* Normalized and Raw S.M.A.R.T. values from 1 upto 255. The data have a different set of S.M.A.R.T. values.\n",
    "\n",
    "The normalized values are sometimes not provided, for examle to return the amount of hours a drive was already running a normalization makes no sence. I decided to only use the raw values. The Ranges of the values are vendor specific. Thats why I decided not to build a model for everything, but instead generate a model specific one.\n",
    "\n",
    "The entire dataset (I call it `raw`) is split into several pieces. Each piece referencing the year and the quarter that this data was extracted from. The following table shows some more detailed information about the dataset:\n",
    "\n",
    "|file|year|quarter(s)|compressed MB|uncompressed MB|files|\n",
    "|--  |  --|       --|           --|             --|   --|\n",
    "|[data_2013.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_2013.zip)|2013|Q1,Q2,Q3,Q4|77|738|266|\n",
    "|[data_2014.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_2014.zip)|2014|Q1,Q2,Q3,Q4|560|2880|365|\n",
    "|[data_2015.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_2015.zip)|2015|Q1,Q2,Q3,Q4|803|4294|366|\n",
    "|[data_Q1_2016.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2016.zip)|2016|Q1|257|1356|92|\n",
    "|[data_Q2_2016.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2016.zip)|2016|Q2|278|1478|92|\n",
    "|[data_Q3_2016.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2016.zip)|2016|Q3|307|1604|92|\n",
    "|[data_Q4_2016.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2016.zip)|2016|Q4|321|1651|92|\n",
    "|[data_Q1_2017.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2017.zip)|2017|Q1|323|1659|90|\n",
    "|[data_Q2_2017.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q2_2017.zip)|2017|Q2|368|1895|91|\n",
    "|[data_Q3_2017.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q3_2017.zip)|2017|Q3|406|2027|92|\n",
    "|[data_Q4_2017.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q4_2017.zip)|2017|Q4|434|2112|93|\n",
    "|[data_Q1_2018.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2018.zip)|2018|Q1|484|2381|90|\n",
    "|[data_Q1_2018.zip](https://f001.backblazeb2.com/file/Backblaze-Hard-Drive-Data/data_Q1_2018.zip)|2018|Q2|502|2472|91|\n",
    "|Total|2013 - 2018|14|5128|26536|1912|\n",
    "\n",
    "For the first years, the data was collected on a year basis, but then starting from 2016, the data was splitted by quarter.\n",
    "\n",
    "The Input Features are the hard drive model, and the returned S.M.A.R.T. values of the drive at the timestamp represented by \"date\". The data is highly unbalanced, as only about 1.8% drives in the reporting period between April 2003 and June 2018 failed (see: [backblaze.com](https://www.backblaze.com/blog/hard-drive-stats-for-q2-2018/)) .\n",
    "\n",
    "As of time writing, Q2 for 2018 was the latest dataset. Note that the amount of information changed over time. From 2013 to 2014, 80 columns of data were collected for each drive. From 2015 to 2017 90 columns of data were collected. For Q2 2018, 104 columns with data was collected. Each reflecting a subset of the possible 256 S.M.A.R.T. \"columns\" with the raw and the normalized value. \n",
    "\n",
    "I choosed as an example the hard drive model \"ST6000DX000\" by Seagate for the visualization part. Examples are provided in \"Exploratory Visualisation\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping and the preferred value-range of each S.M.A.R.T. value was extracted from [wikipedia.org](https://en.wikipedia.org/wiki/S.M.A.R.T.) - I extracted the map to the [helper.py](helper.py) to have a better overview inside the nodebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could extract three groups of features based on the following plots:\n",
    "* Feature that seem to not be correlated to a fail of the given hard drive model\n",
    "* Feature that are supposed to have a correlation, proposed by wikipedia\n",
    "* Feature that seems to have a correlation, based on the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helper import Helper\n",
    "helper = Helper()\n",
    "smart_to_name = helper.smart_to_name()\n",
    "\n",
    "# We also need to define the basic column names, that are also present beside the S.M.A.R.T. values. \n",
    "# They are also extracted to the helper.py\n",
    "column_list = helper.column_list()\n",
    "\n",
    "\n",
    "from preprocessing import Preprocessing # A lot of preprocessing code was extracted, as requested by the first review\n",
    "from kerasalgorithm import KerasAlgorithm\n",
    "from xgboostgbtreealgorithm import XGBoostGbtreeAlgorithm\n",
    "from lightgbmalgorithm import LightGBMAlgorithm\n",
    "from algorithm_runner import AlgorithmRunner # Extracted the complex running logic\n",
    "from winner import Winner # Extract winner logic\n",
    "from searchwithgrid import SearchWithGrid # Own GridSearch Implementation\n",
    "from validation import Validation # Validation class\n",
    "from freestyle import Freestyle # Freestyle visualisation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import sys\n",
    "import requests\n",
    "import shutil\n",
    "import zipfile\n",
    "# see: https://docs.python.org/3/library/concurrent.futures.html\n",
    "from concurrent.futures import Executor, ThreadPoolExecutor\n",
    "import math\n",
    "from math import floor\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from time import time, sleep\n",
    "\n",
    "from traceback import print_stack\n",
    "\n",
    "# This makes sure that my C: drives is not full of the downloaded data...\n",
    "if os.path.exists(os.path.join('D:','capstone')):\n",
    "    os.chdir(os.path.join('D:','capstone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('drives', 'ST6000DX000.csv')):\n",
    "    raise Exception('Please run first the data preprocessing steps, before rerunning this cells as they depend on the preprocessing results!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = pd.read_csv(os.path.join('drives', 'ST6000DX000.csv'), names=column_list, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df.dropna(inplace=True, how='all', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df.rename(columns=smart_to_name, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if any unmapped columns exist, that we have to take a look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'serial_number', 'model', 'capacity_bytes', 'failure',\n",
       "       'Read Error Rate', 'Spin-Up Time', 'Start/Stop Count',\n",
       "       'Reallocated Sectors Count', 'Seek Error Rate', 'Power-On Hours',\n",
       "       'Spin Retry Count', 'Power Cycle Count', 'SATA Downshift Error Count',\n",
       "       'End-to-End error', 'Reported Uncorrectable Errors', 'Command Timeout',\n",
       "       'High Fly Writes', 'Temperature Difference', 'G-sense Error Rate',\n",
       "       'Power-off Retract Count', 'Load Cycle Count', 'Temperature',\n",
       "       'Hardware ECC Recovered', 'Current Pending Sector Count',\n",
       "       '(Offline) Uncorrectable Sector Count', 'UltraDMA CRC Error Count',\n",
       "       'Head Flying Hours', 'Total LBAs Written', 'Total LBAs Read'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no, everything is mapped given a name. Now lets define the plotting method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(feature, df):\n",
    "    plt.boxplot(\n",
    "            [np.array(df[df['failure'] == 0][feature]), np.array(df[df['failure'] == 1][feature])],            \n",
    "            vert=False,\n",
    "            labels=['running: {}'.format(feature),'failed: {}'.format(feature)],\n",
    "            autorange=True, widths=0.9)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature('Read Error Rate', st_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is an example to have no visual correlation between the failing of a drive and this S.M.A.R.T. value. It is not useful in our machine learning context. For most of the features, this is the case.\n",
    "\n",
    "* Preferred: Low Values\n",
    "* Not normalized between different hard drive vendor\n",
    "* Correlation to Fail by Wikipedia: No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAD8CAYAAABNa2y4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAEXBJREFUeJzt3XuQZGV9xvHvAwsBlItxkfLCZtUISlmCMgqJQJaEJIplECEFgcSAWhZlBSLGWwVL1xATI1YlUUoJReEGCy8VBLNeUFFEQC7LLizLzVUCAREUBURFxSz88kef1Xac3ulZunvecb+fqlN1zun3fc/v7d7qZ87bPbOpKiRJUju2mu8CJEnSrzKcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJKkxhrMkSY1ZNN8FaGFavHhxLV26dL7LkKQFZc2aNd+vql1na2c4a7MsXbqU1atXz3cZkrSgJLljmHYua0uS1BjDWZKkxhjOkiQ1xnCWJKkxhrMmb/nO812BJDXNcJYkqTGGsyRJjTGcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJKkxhrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJM1BkrFfw3CWJKkxhrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJDXGcJYkqTGGsyRJjTGcJUlqjOEsSVJjRhrOSU5KckuSczfRZirJ+7v945KcPsdr/G+SxbO0WZHk9iRru+2KOV5jeZI3zXB+lySvn8tYfeN9u6+etUl2mUP/OT9PkqSFa9GIx3s9cEhV3TWoQVWtBlaP+LozeXNVnTfiMXehN8cPbkbff62q9424nlklWVRVGwYdb6JfgFTVo2MtUJL0a0Z255zkDOAZwIVJTk7yoiRXJrkuyRVJ9uzaLUvymRn675rkk0mu6bYXd+efmOSLSW5KchaQx1Dj8iRnJ7kkyW1JTup77JQk30hyObDngCHeAzyzu/M9LT2nJbkxyQ1JjppjPcclOT/J55N8M8l7+x47vqtnFfDiAf0f181nVfc8H9Y37sokFwNf7p7zy5KsBG7u2ryxq/vGJG/ozi1Nsj7JOcCNwO5zmY8kaTRGdudcVSckeQlwcFV9P8lOwIFVtSHJIcA/AUdsYoh/p3d3eXmSJcAXgOcA7wQur6p/SPIy4DUbOyT5HPDaqrp7hvFOS/L2bv+mqjq22382cDCwI7A+yYeA5wFHA/vQe06uBdbMMObbgOdW1T7d9Y/o+uwNLAauSXJpVd0zQ9+Tk/xlt/9AVR3c7e8DPB94uKvnA8AG4F3AvsCDwFeA62YY8xTg4qp6dbdMvirJl7rHXgA8r6ruT7KsO35uVd2eZF/geGA/ej/sXJ3kq8ADwLOAv66qq2a4niRpAka9rN1vZ+A/kzwLKGCbWdofAuzVW00FYKckjwcOAl4JUFWfTfLAxgZVdegmxhu0rP3ZqnoYeDjJvcBuwIHABVX1E4DuDnMYBwAfq6pHgO92AfdCYKb+g5a1v1xVD3bXvRn4HXpBf0lVfa87/wlgjxn6/gnwZ32fj28HLOn2L6qq+/varqqq2/vqvqCqHurGP5/ec7ASuGNQMCd5HfA6gCVLlszUZGh9r7MkaZpxhvOpwFeq6vAkS4FLZmm/FbB/Vf2s/+QY3sQf7tt/hE08B0l2Bz7dHZ4BfH6YCyR5N/AygI132aOoZ6ZLAUdU1fpp198PeGha2+nHgwxsV1VnAmcCTE1N1RzqnGmsx9JdkubNJG4uxvmrVDsD3+72jxui/ReBEzceJNkYapcCx3TnXgo8YXQl/sKlwCuSbJ9kR+DlAFX1rarap9vOAH5Ebzl8o8uAo5JsnWRXenf5q6rqlI39NrOeq4E/6D5v3wb48wHtvgCc2H15iyTPH3L8y+jNd4ckjwMO785JkhowznB+L/DPSa5juLvBk4CpJOu65d0TuvPvAg5KchO95e07N3ZI8rkkTxkw3mn51V9d2nbQhavqWuATwPXAhcA1A9rdB3yt+xLVacAFwLqu38XAW6rqOwMuc/K0epZuop57gOXAlcDXgFsGND2V3scF67rn59RBY04b/1pgBbCK3g8CZ1XVTJ9pS5LmQVxe1OaYmpqq1as38zfilu8Myx8cbUGSNCFJNvujuSRrqmpqtnb+hTBJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJKkxhrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJDXGcJYkaQ6qauzXMJwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJDXGcJYkqTGGsyRJjTGcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJKkxhrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZw1ecsfnO8KJKlphrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZw1ect3nu8KJKlphrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJDXGcJYkqTGGsyRJjTGcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJGkOkoz9GoazJEmNMZwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJDXGcJYkqTGGsyRJjTGcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJKkxhrMkSY0xnCVJaozhLElSYwxnSZIaM6/hnOSsJHuNYdxLkqxPsrbbzptj/xVJjpzh/NIkx2xGPSuS3N5XzxVz7L88yZvmel1J0sK0aNiGSQKkqh4d1cWr6rWjGmsGx1bV6hGPuRQ4BvjoZvR9c1XN6YeEUUiyqKo2DDoetp8kaXI2eefc3SmuT3IOcCOwe5If9z1+ZJIV3f6KJO9PckWS2zbeeSZZ1t3Jnpfk60nO7YJ+4x3uVLf/4yTvTnJ9kquS7Nadf2Z3fEOSf+y//lxtosYkOb2b65eAJw0Y4j3Agd3d78lJtkvy4a6265IcPMd6lic5u3sebktyUt9jpyT5RpLLgT0H9N81ySeTXNNtL+4b9yNJvgZ8JMlxSVYmuRj4cjff05Lc2NV+VNdvWZLLkqwEbp7LXCRJI1RVAzd6d4qPAvv3nftx3/6RwIpufwXwX/QCfy/g1u78MuBB4GndY1cCB3SPXQJMdfsFvLzbfy/w9m7/M8BfdPsnTLv+2gF1XwKsB9Z222mz1PhK4CJga+ApwA+AI2cYdxnwmb7jvwPO7vafDdwJbDdDvxXA7X31nNudXw5cAfwWsBi4D9gG2Be4AdgB2Am4FXjTDON+tO+5XALc0jfuGmD77vg44C7gt7vjI/rmu1tX95O7+T0EPH3A8/o6YDWwesmSJbXZ3rlTda+3m5ub24LcNheweqb31+nbMMvad1TVVUO0A/hU9Za9b95459tZVVV3ASRZSy/0L5/W9+f0ghh6wfLH3f7vAa/o9j8KvG9jh6raZxO1DFrWnqnGg4CPVdUjwN3dHeYwDgA+0NXy9SR3AHsA62ZoO2hZ+7NV9TDwcJJ76YXlgcAFVfUTgO5OdiaHAHt1CxEAOyV5fLe/sqp+2tf2oqq6v6/ujfP9bpKvAi8Efkjvtbp9potV1ZnAmQBTU1M1oKah9P6NStLC0/eeOzbDhPND047731W3m/bYw337GXD+kQHX/b/65Tv2oDajMKjGX5NkP+A/usN30AuvWSX5MPB84O6qOnQO9cx13lvRW9X42bTrw6+/btOPBxm2nSRpTDbn29rfTfKcJFsBh4+6oBlcRW8ZFuDoMV3jUuCoJFsneTJwMEBVXV1V+3TbSuBHwI59/S4DjgVIsge9peX1VXV812e2YN5UPa9Isn2SHYGXD2j3ReDEjQdJNrWS0O8yfjnfXemtHKzazFolSSO2OeH8NnrLz1cA94y2nBm9AXhjknXA79L7/Br4xRL5IOf2/erSl2a5xgXAN+l9Ceocep+Lz2Qd8Ej3pbWTgQ8CWyW5AfgEcFy3RD2T0/rqWZtk20HFVNW13XjXAxcC1wxoehIwlWRdkpvpfSY/jAu6uVwPXAy8paq+M2RfSdKYpfXP/pLsAPy0qirJ0fS+HHbYfNe1pZuamqrVqzfzN9WW7wzLH5y9nSQ1KMlmf28myZqqmpqt3bg+1x2lfYHTu1+/+gHw6nmuR5KksWo+nKvqMmDv+a5DkqRJ8W9rS5LUGMNZkqTGGM6SJDXGcJYkqTGGsyRJjTGcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnCWJKkxhrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkzUFVjf0ahrMkSY0xnCVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmNMZwlSWqM4SxJUmMMZ0mSGmM4S5LUGMNZkqTGGM6SJDXGcJYkqTGGsyRJjTGcJUlqjOEsSVJjDGdJkhpjOEuS1BjDWZKkxhjOkiQ1xnDW5C1/cL4rkKSmGc6SJDXGcJYkqTGGsyRJjTGcJUlqTKpqvmvQApTke8Adm9l9MfD9EZazEDjnLYNz3jI8ljn/TlXtOlsjw1kTl2R1VU3Ndx2T5Jy3DM55yzCJObusLUlSYwxnSZIaYzhrPpw53wXMA+e8ZXDOW4axz9nPnCVJaox3zpIkNcZw1tgkeUmS9UluTfK2GR5Pkvd3j69L8oL5qHOUhpjzsd1cb0hyRZK956POUZptzn3tXphkQ5IjJ1nfOAwz5yTLkqxNclOSr066xlEb4t/2zkk+neT6bs7Hz0edo5Lk7CT3JrlxwOPjff+qKje3kW/A1sD/AM8AtgWuB/aa1uZQ4EIgwP7A1fNd9wTm/PvAE7r9l24Jc+5rdzHwOeDI+a57Aq/zLsDNwJLu+EnzXfcE5vz3wL90+7sC9wPbznftj2HOBwEvAG4c8PhY37+8c9a4vAi4tapuq6qfAx8HDpvW5jDgnOq5CtglyZMnXegIzTrnqrqiqh7oDq8CnjbhGkdtmNcZ4ETgk8C9kyxuTIaZ8zHA+VV1J0BVLfR5DzPnAnZMEuDx9MJ5w2TLHJ2qupTeHAYZ6/uX4axxeSrwrb7ju7pzc22zkMx1Pq+h95P3QjbrnJM8FTgc+NAE6xqnYV7nPYAnJLkkyZokr5pYdeMxzJxPB54D3A3cAPxtVT06mfLmxVjfvxaNaiBJw0tyML1wPmC+a5mAfwPeWlWP9m6qtgiLgH2BPwK2B65MclVVfWN+yxqrPwXWAn8IPBO4KMllVfXD+S1rYTKcNS7fBnbvO35ad26ubRaSoeaT5HnAWcBLq+q+CdU2LsPMeQr4eBfMi4FDk2yoqk9NpsSRG2bOdwH3VdVDwENJLgX2BhZqOA8z5+OB91TvA9lbk9wOPBtYNZkSJ26s718ua2tcrgGeleTpSbYFjgZWTmuzEnhV963H/YEHq+qeSRc6QrPOOckS4Hzgr35D7qJmnXNVPb2qllbVUuA84PULOJhhuH/b/w0ckGRRkh2A/YBbJlznKA0z5zvprRSQZDdgT+C2iVY5WWN9//LOWWNRVRuS/A3wBXrf9Dy7qm5KckL3+Bn0vrl7KHAr8BN6P3kvWEPO+R3AE4EPdneSG2oB/6cBQ875N8owc66qW5J8HlgHPAqcVVUz/krOQjDk63wqsCLJDfS+wfzWqlqw/1tVko8By4DFSe4C3glsA5N5//IvhEmS1BiXtSVJaozhLElSYwxnSZIaYzhLktQYw1mSpMYYzpIkNcZwliSpMYazJEmN+X8RSQ14JbF3awAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e2afb21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature('End-to-End error', st_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the feature `End-to-End error`, we have the same boxplot for failed and for running devices. This value should be the count of parity errors. Its also interisting that this value is normalized from 0 upto 1. The representation as \"error count\" is not obvious at this point from a user perspective. From this representation I can't see an possible correlation with a failing drive. \n",
    "\n",
    "* Preferred: Low\n",
    "* Correlation to Fail by Wikipedia: Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e70dd3c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature('Reported Uncorrectable Errors', st_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the interisting features was `Reported Uncorrectable Errors` - this indeed looks very promising to be correlated to a hard drive fail, as the range of fail hard drives jumps upto 12 instead of being lower than 2.\n",
    "\n",
    "* Referred: Low\n",
    "* Correlation to Fail by Wikipedia: Yes\n",
    "* **Correlation to Fail by given plot: Yes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e5b1f2ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature('Current Pending Sector Count', st_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature `Current Pending Sector Count` seems to be a possible feature for predictions. Values above approx. 80 are only present for failing drives. This feature indicates the amount of \"unstable\" sectors on the hard drive.\n",
    "\n",
    "* Preferred: Low\n",
    "* Correlation to Fail by Wikipedia: Yes\n",
    "* **Correlation to Fail by given plot: Yes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18ef10044a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature('(Offline) Uncorrectable Sector Count', st_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature indicates the total count of uncorrectable errors while reading or writing. From the plot I assume a correlation between the fail of a hard drive and a value above approx. 80.\n",
    "\n",
    "* Preferred: Low\n",
    "* Correlation to Fail by Wikipedia: Yes\n",
    "* **Correlation to Fail by given plot: Yes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms and Techniques\n",
    "\n",
    "So fare we have worked with more balanced data and tried several algorithms against this datasets. But for heavy unbalanced data, I have no clue what algorithm to choose, so lets just try a lot of them and compare the results against each other based on their fbeta score! I searched some classfiers that I could found in scikit-learn and use them:\n",
    "\n",
    "\n",
    "### SVC\n",
    "\n",
    "A Support Vecotor Machine create a initial random function. This function is than used to calculate the distance of each point in the dataset. For each class in the dataset, the algorithm tries to maximaize the distance to this point. The function is slightly ajusted after each iteration and again compared with the previous results. As better the separation is possible, as better SVC works.\n",
    "\n",
    "### Decision Trees\n",
    "\n",
    "[reference](https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248)\n",
    "\n",
    "Measuring the entroy to find a way to split the data and than reduce the amount of nodes to simlplity it and prevent an overfitting.\n",
    "\n",
    "### LinearSVC\n",
    "\n",
    "A Linear Support Vector Machine works the the genral svc, but only uses linear functions.\n",
    "\n",
    "### SGDClassifier\n",
    "\n",
    "generate a linear function. ask one point of the dataset, if the linear function line should move closer to the point or not. You can move the line by changing the parameters of the linear function. To measure the qualitiy we use a error function.\n",
    "\n",
    "###  NearestCentroid\n",
    "For each class calculate the mean of this data points. To generate a prediction, compare the distance to each center and return the shortest one.\n",
    "\n",
    "### Naive Bayes\n",
    "Caclulating that something is of kind \"a\" and calculating the probability that something is **not** of kind \"a\" - he higer value wins. The Naive approach is that the event of kind \"a\" is not related to any other event that is analysed.  Gaussian assumes that the total probability is distribibuted as a gaussian distribution.\n",
    "\n",
    "### AdaBoost\n",
    "AdaBoost used several instance of a algorithm, so called \"weak learner\". Each of this weak learners is doing a good job for a very small set of the data. This weak learners get each combined and boosted, according to their accuracy. The weak learners are often Decision Trees.\n",
    "\n",
    "and boosts each result of this algorithm to even better fit the  data and improve the overall result.\n",
    "\n",
    "### Random Forest\n",
    "Instead of calculating one Decision Tree, Random Forest generates several Trees and all decide by themself. The majority of the outcomes by each Tree returns the final outcome by the tree.\n",
    "\n",
    "### Multilayer Perceptron\n",
    "A Perceptron is a adaption of a neuron inside human brains. A signal (data) goes in and a signal gets returned and transferred to another perceptron. The signal can be either reduced or increased, depending on the activision function of the perceptron. Perceptrons are organized in layers. Depending of the amount of layers, as more complex mathematical problems can be solved by the layers.\n",
    "\n",
    "Each perceptron is initialized by a random value at the beginning. The first signal gets transferred over each layer. After finishing at the end, the weights of each connection gets updated (called backpropagation) to improve the accuracy of the network. Then the next signal passes and the process of backpropagation is repeated. The amount of repeating this process is one of the Hyperparameters of the Algorithm.\n",
    "\n",
    "Most of this algorithms where run with their default settings. A different set of parameters could improve their results, but I wanted to have some all more or less good comparable based on their default settings.\n",
    "\n",
    "I also tried a `Keras` neuronal network, `LightGBM` and `XGBoost` to even extend the amount of algorithms that are compared. For the last 3 algorithms I used a train, test and validation set. The validation set was used by the algorithm to improve. All tests sets where run after the model was generated to calculate the fbeta score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "Googles(Eduardo Pinheiro et al.) results are as follows (link provided above, summary see wikipedia link):\n",
    "\n",
    "* 60 days after finding uncorrectable errors (S.M.A.R.T. Value 198), the drive had 39 times higher change to fail\n",
    "First errors in S.M.A.R.T. 196 (Relocation) and 5 (offline Relocation) are strongly correlated to higher probabilities of failure\n",
    "* 56% of the drives failed without recording any count in the four string S.M.A.R.T. Warnings (Scan Errors, Relocation Count, offline Relocation and probiatinal Count)\n",
    "* 36% Failed without any S.M.A.R.T. error at all\n",
    "\n",
    "This lets me create the benchmark model as following:\n",
    "The total amount of fails is 1.84% for all drives. \n",
    "This 1.84% can now be splitted into three groups, provided using the google paper:\n",
    "\n",
    "Fails without errors: $1.84 \\cdot 0.36 = 0.6624 %%$\n",
    "\n",
    "Fails with any smart warning: $1.84 \\cdot 0.56 = 1.0304 %$\n",
    "\n",
    "Fails that could be predicted: $1.84 \\cdot (1 - 0.36 - 0.56) = 0.8 %$ \n",
    "\n",
    "The Benchmark model, using random choice, predict with a change of 0.8% that a drive will fail. Each model have different chance to fail, this means that the 0.8 % is the average probability over every model in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the current directories that we will use. \n",
    "* raw - contains the raw zip files, downloaded from backblaze\n",
    "* drives - contains a csv file for each hard drive model\n",
    "* train - contains the training set for each hard drive model as csv\n",
    "* test - contains the test set for each hard drive model as csv\n",
    "* validate - contains the validation set for each hard drive model as csv\n",
    "* tmp - temp directory for splitting and normalization\n",
    "* drives_minified - removed every non relevant data and feature from a given hard drive\n",
    "* sklearn_models - containing models and results of sklearn algorithms\n",
    "* keras_models - containing models and results for keras\n",
    "* xgboost_models - containing models and results for xgboost\n",
    "* lightgbm_models - containing models and results for lightgbm\n",
    "\n",
    "When using the preprocessed data referenced in the README.md, some of this directories will already exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Unpacking and path fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 1625.51it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessing = Preprocessing()\n",
    "preprocessing.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 8670.05it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessing.unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.rename() # To make sure each directory extracted have a normalized name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "backblaze regularly add new S.M.A.R.T. values to their generated ouput. The new values are provided somewhere in \"between\" of existing values. The header of each files is:\n",
    "* date - date the drive information was recorded\n",
    "* serial numer of the drive\n",
    "* the model\n",
    "* the capacity\n",
    "* the failure indicator\n",
    "* then for each smart value the normalized and the raw value\n",
    "\n",
    "The S.M.A.R.T. values are always in a increasing order upto 255. Adding new S.M.R.A.R.T columns, means adding them inbetween the existing ones. Reading the entire dataset is not possible, as the amount of memory required for this operation hits the 32 GB limit. Instead, the normalization have to be done directly on the files without reading everything at once.\n",
    "\n",
    "I created two methods: `extract_smart_values` and `fill_content`.\n",
    "`extract_smart_values` returns a map of an a colum to a appropriate smart value. Using this map, I can now add \"blanks\" to the dataset, to make sure that every file afterwords, have the same structure. I use `fill_content` for this approach. Both where moved to the [helper.py](helper.py) to reduce the amount of code inside this notebook a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting by drive model\n",
    "Some S.M.A.R.T. values are manufacture specific (see wikipedia article), you can't compare them between different manufacture. Sometimes the same value can have a different meaning and finally some models inside a manufacture can be add or removed comparing to different models. This forces us to split the entire dataset by hard drive type. As we have to go over several GB of csv data, this process takes over 1h on my device... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.split_by_drive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything went well, we can now move the files to the destination target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.split_by_drive_move()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unfortunately the data is now very huge and not all models could be read into ram after the splitting and calculating the models, so I had again to now transformn the data in a minified version, removing the before created empty spaces to reduce the file size - but now the data is consistent in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now triggering the minification, took 6h on my device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [5:56:57<00:00, 200.16s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "total_files = glob.glob(os.path.join('drives','*.csv'))\n",
    "with tqdm(total=len(total_files)) as pbar:\n",
    "    for file in total_files:\n",
    "        preprocessing.minify(file)\n",
    "        pbar.update(1)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a non failure, its ok to split the data randomly. But for failed drives, I really want to make sure to have an equal distribution over the entire dataset. Before we calculate the amount of failed drives for each model, and than split them according to the failure. \n",
    "\n",
    "If we have  a failed drive, we fist move the drives to the train dataset and reduce the total amount of drives we need for it. When the train set is \"full\", we add them to the test set and finally later add them to the validation set. this makes sure that we have a equal distribution of failed drives in every set. Otherwise, their can be a chance that we have no drive inside the train, test or validation group as we are dealing with a heavely unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('qualified.csv'):\n",
    "    all_drives = glob.glob(os.path.join('drives_minified', '*.csv'))\n",
    "    drive_metrics = Parallel(n_jobs=-1, backend=\"multiprocessing\", verbose=1)(delayed(preprocessing.drive_metrics)(file) for file in all_drives)\n",
    "    qualified_df = pd.DataFrame(drive_metrics)\n",
    "    # Only include drives that have at least 3 failure records.\n",
    "    qualified_df = qualified_df[qualified_df['failure'] >= 3]\n",
    "    # Sort by lines, as small files are less compuation heavy and the long running tasks can run over night \n",
    "    #- but debugging can be done in faster iterations\n",
    "    qualified_df.sort_values(by='lines', inplace=True)\n",
    "    qualified_df.to_csv('qualified.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As now the data is splitted, we have to make sure that the appropriate drives always include some fail drives, otherwise we can't do any training. Took after the minification only several minutes. Before the minification implemented, this took 20 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting by Train, Test and Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table now shows all our drives that we take a closer look at. As even more challenging, I also included drives that only have a small amount of fails. I assume as more failure are in general present, the more easy it is for an algorithm to generate a prediction for. We will take a look at it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `final_split` function, we will now split the extracted models into a train, test and validation set according to the calculations we made before. As the extracted fail rate can be very slow, I use the previously calculated train, test and validation counts to make sure that they are present in the appropriate set and not get \"randomly\" moved to a different set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [07:24<00:00,  7.41s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Run this sequencially, as I got corrupted data otherwise :-|\n",
    "with tqdm(total=len(qualified_df)) as pbar:\n",
    "    for _i, row in qualified_df.iterrows():\n",
    "        preprocessing.final_split(row)\n",
    "        pbar.update(1)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finally doing sucessfully the preprocessing, we can now start to run the algorithms. For a more detail implementation, see [algorithm_runner.py](algorithm_runner.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FakeAlgorithm`\n",
    "FakeAlgorithm is our benchmark algorithm that we need as a reference to compare against. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeAlgorithm:\n",
    "    def fit(self, X, y):\n",
    "        # Nothing to calculate\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X - feature matrix to generate predictions for.\n",
    "        returns a list with 0 and 1 for each row in the feature matrix.\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            y_pred.append(int(random.random() <= 0.08))\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DecisionTreeClassifier` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "`DecisionTreeClassifier` builds up a tree of decisions. Hyperparamers are `max_depth`, reflecting the level that the tree can get (default to no limit), `min_samples_leaf ` reflect the number of minimal samples that should be inside a node (defaults to 1)\n",
    "\n",
    "\n",
    "###  `LinearSVC` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "`LinearSVC` \"Similar to SVC with parameter kernel=’linear\" -   hyperparameters: `tol` as the value for  the stopping criteria (defaults to 1e-4)and `max_iter ` the amount of iterations to run the algorithm.\n",
    "\n",
    "### `SGDClassifier` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
    "`SGDClassifier` stochastic gradient descent. Hyperparameters: `tol` as the stop criterion. Set to 1-e3 as the new default value for sklearn 0.21. `max_iter` is the amount of iterations the algorithm should run.\n",
    "\n",
    "### `NearestCentroid` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestCentroid.html#sklearn.neighbors.NearestCentroid)\n",
    "\n",
    "\"Each class is represented by its centroid, with test samples classified to the class with the nearest centroid.\" \n",
    "\n",
    "### `GaussianNB` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "\n",
    "\"Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of independence between every pair of features.\" - I choosed the `GaussianNB` as it seems to be the most used one. No Hyperparameters are present.\n",
    "\n",
    "### `AdaBoostClassifier` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n",
    "\n",
    "The Hyperparameters are `base_estimator`, thats the base algorithm to use the number of instances reflected by `n_estimators` (default 50)  and the `learning_rate` (default 1.0)\n",
    "\n",
    "### `RandomForestClassifier` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "\n",
    "\"A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting.\" Compared to `AdaBoostClassifier`, no boosting is used. The Hyperparameters are `n_estimators` (default 10) and the number of levels to go deep with `max_depth`\n",
    "\n",
    "### `MLPClassifier` [doc](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
    "\n",
    "`MLPClassifier` implements a Perceptron Classifier with 100 Hidden Layers described by `hidden_layer_sizes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [\n",
    "    FakeAlgorithm(),\n",
    "    DecisionTreeClassifier(),\n",
    "    LinearSVC(),\n",
    "    SGDClassifier(max_iter=1000, tol=1e-3), # defaults in sklearn 0.21\n",
    "    NearestCentroid(),\n",
    "    GaussianNB(),\n",
    "    AdaBoostClassifier(n_estimators=100),\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "    MLPClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all of the relevant sklearn algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified_df = pd.read_csv('qualified.csv')\n",
    "\n",
    "clf_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ST4000DM000.csv: 100%|██████████| 60/60 [04:19<00:00, 31.57s/it]            \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(qualified_df)) as pbar:\n",
    "    for _i, row in qualified_df.iterrows():\n",
    "\n",
    "        drive_csv = row['drive_csv']\n",
    "        lines = row['lines']\n",
    "        try:\n",
    "            pbar.set_description(drive_csv)\n",
    "            \n",
    "            # I don't use prepare_parallel, as the validation set is not needed and memory is everything...\n",
    "            (X_train, y_train) =  AlgorithmRunner.prepare_train(drive_csv)\n",
    "            (X_test, y_test) = AlgorithmRunner.prepare_test(drive_csv)\n",
    "            \n",
    "            # For the biggeest drive model, not run all algorithms in parallel to prevent out of memory errors.\n",
    "            # Also only using some algorithms, as the runtime is just to huge even after runnning over night :-(\n",
    "            if lines > 20000000:\n",
    "                for clf in [FakeAlgorithm(), GaussianNB(), NearestCentroid()]:\n",
    "                    result = AlgorithmRunner.run_parallel(clf, drive_csv, X_train, y_train, X_test, y_test)\n",
    "                    clf_results.append(result)\n",
    "            else: \n",
    "                # Run all algorithms in parallel with shared memory to have low memory overhead - its getting warm now :-D\n",
    "                parallel_results = Parallel(n_jobs=-1, backend=\"threading\")(delayed(AlgorithmRunner.run_parallel)(clf, drive_csv, X_train, y_train, X_test, y_test) for clf in clfs)\n",
    "                for result in parallel_results:\n",
    "                    clf_results.append(result)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(\"error {} in: {}\".format(drive_csv, err))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `SVC` [doc](http://scikit-learn.org/stable/modules/svm.html#svm-kernels)\n",
    "`SVC` Support Vector Classifier tries to maximize the distance between (in our case 2) classes. This separation line is called hyperplane. At least `C` and the `kernel` should be mentioned here as hyperparameters. `C` that is the penalty parameter for the error term and the `kernel` to be choosen. `C` defaults to 1.0 and `kernel` to `rbf`. Running SVC only for all models as this seems to be the most computing intensive algorithm - running over the night. Please note that SVC works not that good for non normalized data, so the expected results should be not that good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVC for ST4000DM000.csv: 100%|██████████| 60/60 [00:02<00:00, 28.11it/s]            \n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(qualified_df)) as pbar:\n",
    "    for _i, row in qualified_df.iterrows():\n",
    "\n",
    "        drive_csv = row['drive_csv']\n",
    "        lines = row['lines']\n",
    "        try:\n",
    "            pbar.set_description('SVC for {}'.format(drive_csv))\n",
    "            # Again the calculation time is to high, skipping...\n",
    "            if lines < 50000:\n",
    "                (X_train, y_train) = prepare_train(drive_csv)\n",
    "                (X_test, y_test) = prepare_test(drive_csv)\n",
    "                result = AlgorithmRunner.run_parallel(SVC(), drive_csv, X_train, y_train, X_test, y_test)\n",
    "                clf_results.append(result)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(\"error {} in: {}\".format(drive_csv, err))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results.csv'):\n",
    "    results_df = pd.DataFrame(list(clf_results))\n",
    "    results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "Keras is a framwork implementing an abstract layer for several neuronal network / perceptron \"backends\" - I assumed that is should perform better than the `MLPClassifier` from sklearn. I used the tensorflow backend. For Keras I used a more explicit architecture: The amount of each layer is reduced by 10% of the total amount of features to have a smoth lowering of the amount of layers, stopping at 2 features to add a final Dense 1 layer with the sigmoid function. All other hidden layers use the relu function. For more Details, see [kerasalgorithm.py]([kerasalgorithm.py]). This algorithm is using a validation set to for a direct improvement / feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KerasAlgorithm for ST4000DM000.csv: 100%|██████████| 60/60 [03:37<00:00, 27.51s/it]            \n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "qualified_df = pd.read_csv('qualified.csv')\n",
    "keras_results = []\n",
    "with tqdm(total=len(qualified_df)) as pbar:\n",
    "    for _i, row in qualified_df.iterrows():\n",
    "\n",
    "        drive_csv = row['drive_csv']\n",
    "        lines = row['lines']\n",
    "        try:\n",
    "            # Special case for keras: we need to pass the drive_csv name to create a valid checkpoint file path\n",
    "            clf = KerasAlgorithm(drive_csv)\n",
    "            pbar.set_description('{} for {}'.format(clf.__class__.__name__, drive_csv))\n",
    "            (X_train, y_train, X_test, y_test, X_valid, y_valid) =  AlgorithmRunner.prepare_parallel(drive_csv)\n",
    "            result =  AlgorithmRunner.run_parallel(clf, drive_csv, X_train, y_train, X_test, y_test, X_valid, y_valid)\n",
    "            keras_results.append(result)\n",
    "            K.clear_session()\n",
    "\n",
    "        except Exception as err:\n",
    "            print(\"error {} in: {}\".format(drive_csv, err))\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results_keras.csv'):\n",
    "    results_df_keras = pd.DataFrame(keras_results)\n",
    "    results_df_keras.to_csv('results_keras.csv', index=False)\n",
    "results_df_keras = pd.read_csv('results_keras.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "The XGBoost Framework implements a gradient boosting algorithm. I can be compared to [Adaboost](#AdaBoostClassifier-doc). To  be able to compare XGBoost with lightgbm, also a boosting algorithm, I set the `max_depth` Hyperparameter to 30, the learning rate `eta` to `0.01` and as `objective` used `binagry:logistic`. I also used a validation set for this Algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XGBoostGbtreeAlgorithm for ST4000DM000.csv: 100%|██████████| 60/60 [03:40<00:00, 27.89s/it]            \n"
     ]
    }
   ],
   "source": [
    "qualified_df = pd.read_csv('qualified.csv')\n",
    "xgboost_results = []\n",
    "with tqdm(total=len(qualified_df)) as pbar:\n",
    "    for _i, row in qualified_df.iterrows():\n",
    "\n",
    "        drive_csv = row['drive_csv']\n",
    "        lines = row['lines']\n",
    "        try:\n",
    "            clf = XGBoostGbtreeAlgorithm()\n",
    "            pbar.set_description('{} for {}'.format(clf.__class__.__name__, drive_csv))\n",
    "\n",
    "            (X_train, y_train, X_test, y_test, X_valid, y_valid) =  AlgorithmRunner.prepare_parallel(drive_csv)\n",
    "            result =  AlgorithmRunner.run_parallel(clf, drive_csv, X_train, y_train, X_test, y_test, X_valid, y_valid)\n",
    "            xgboost_results.append(result)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(\"error {} in: {}\".format(drive_csv, err))\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results_xgboost.csv'):\n",
    "    results_df_xgboost = pd.DataFrame(xgboost_results)\n",
    "    results_df_xgboost.to_csv('results_xgboost.csv', index=False)\n",
    "results_df_xgboost = pd.read_csv('results_xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM [Code Idea](https://github.com/Microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py)\n",
    "Another Framework containing several boposting algorithms. I used the **G**radient **B**oosting **D**ecision **T**ree as boosting type. Again this is close to [Adaboost](#AdaBoostClassifier-doc). I choosed the same `learning_rate` as for XGboost of 0.01 with a `objective` of `binary`. The validation set was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBMAlgorithm for ST4000DM000.csv: 100%|██████████| 60/60 [03:44<00:00, 28.69s/it]            \n"
     ]
    }
   ],
   "source": [
    "qualified_df = pd.read_csv('qualified.csv')\n",
    "total_items = len(qualified_df)\n",
    "lightgbm_results = []\n",
    "with tqdm(total=total_items) as pbar:\n",
    "    for _i, row in qualified_df.iterrows():\n",
    "\n",
    "        drive_csv = row['drive_csv']\n",
    "        lines = row['lines']\n",
    "        try:\n",
    "            clf = LightGBMAlgorithm()\n",
    "            pbar.set_description('{} for {}'.format(clf.__class__.__name__, drive_csv))\n",
    "\n",
    "            (X_train, y_train, X_test, y_test, X_valid, y_valid) =  AlgorithmRunner.prepare_parallel(drive_csv)\n",
    "            result =  AlgorithmRunner.run_parallel(clf, drive_csv, X_train, y_train, X_test, y_test, X_valid, y_valid)\n",
    "            lightgbm_results.append(result)\n",
    "\n",
    "        except Exception as err:\n",
    "            print(\"error {} in: {}\".format(drive_csv, err))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('results_lightgbm.csv'):\n",
    "    results_df_lightgbm = pd.DataFrame(lightgbm_results)\n",
    "    results_df_lightgbm.to_csv('results_lightgbm.csv', index=False)\n",
    "results_df_lightgbm = pd.read_csv('results_lightgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_result = Winner.calculate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement\n",
    " \n",
    "As different algorithms have won, I choose the drives where the `DecisionTreeClassifier` is the winner to further improve them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WDC WD800AAJS.csv: 100%|██████████| 12/12 [24:40<00:00, 213.64s/it]\n"
     ]
    }
   ],
   "source": [
    "merged_result = Winner.calculate()\n",
    "all_drives = list(merged_result[merged_result['winner'] == 'DecisionTreeClassifier']['drive_csv'])\n",
    "\n",
    "if not os.path.exists('grid_search.csv'):\n",
    "    grid_search = []\n",
    "    with tqdm(total=len(all_drives)) as pbar:\n",
    "        for drive_csv in all_drives:\n",
    "            pbar.set_description(drive_csv)\n",
    "            grid_search.append(SearchWithGrid.run(drive_csv))\n",
    "            pbar.update(1)\n",
    "    SearchWithGrid.calculate_best(grid_search)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the initial fbeta score, the default parameters where used:\n",
    "* criterion=\"gini\"\n",
    "* splitter='best'\n",
    "* max_depth=None\n",
    "* min_samples_split=2\n",
    "\n",
    "for the new fbeta score, max_depth of None also returned the best results. The new fbeta score was rounded.\n",
    "\n",
    "|drive|fbetascore initial|fbetascore grid search|criterion|splitter|min_samples_split|\n",
    "|---|---|\n",
    "|ST4000DM005.csv|0.499613|0.499613|gini|best|2\n",
    "|ST4000DM001.csv| 0.499845|0.499897|gini|best|2\n",
    "|ST3160318AS.csv|0.499849|0.499849|gini|best|2\n",
    "|WDC WD20EFRX.csv| 0.499889|0.49993|gini|random|2\n",
    "|ST250LM004 HN.csv|0.499895|0.499895|gini|best|2\n",
    "|ST9250315AS.csv|0.499911|0.499911|gini|best|4\n",
    "|ST32000542AS.csv|0.499916|0.499916|gini|best|2\n",
    "|ST3160316AS.csv|0.499922|0.499922|gini|best|2\n",
    "|ST31500541AS.csv|0.528457|0.543369|entropy|best|3\n",
    "|ST8000DM002.csv|0.566657|0.607134|gini|random|5\n",
    "|WDC WD60EFRX.csv|0.611081|0.681788|gini|best|2\n",
    "|WDC WD800AAJS.csv|1.0|1.0|gini|best|3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Model Evaluation and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4791606315695175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_result = Winner.calculate()\n",
    "np.mean(merged_result['FakeAlgorithm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_results = Validation.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look a t the variance of the fbeta score over 6 runs of a kfold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>FakeAlgorithm</th>\n",
       "      <th>drive_csv</th>\n",
       "      <th>winner_f_beta</th>\n",
       "      <th>maximal_fbeta</th>\n",
       "      <th>mean_fbeta</th>\n",
       "      <th>minimal_fbeta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499613</td>\n",
       "      <td>0.476075</td>\n",
       "      <td>ST4000DM005.csv</td>\n",
       "      <td>0.499613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499845</td>\n",
       "      <td>0.480548</td>\n",
       "      <td>ST4000DM001.csv</td>\n",
       "      <td>0.499845</td>\n",
       "      <td>0.049977</td>\n",
       "      <td>0.049977</td>\n",
       "      <td>0.049977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.499849</td>\n",
       "      <td>0.479243</td>\n",
       "      <td>ST3160318AS.csv</td>\n",
       "      <td>0.499849</td>\n",
       "      <td>0.257868</td>\n",
       "      <td>0.249474</td>\n",
       "      <td>0.207874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.479679</td>\n",
       "      <td>WDC WD20EFRX.csv</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>0.149917</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.049986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.478194</td>\n",
       "      <td>ST250LM004 HN.csv</td>\n",
       "      <td>0.499895</td>\n",
       "      <td>0.149615</td>\n",
       "      <td>0.074843</td>\n",
       "      <td>0.049752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.499911</td>\n",
       "      <td>0.480173</td>\n",
       "      <td>ST9250315AS.csv</td>\n",
       "      <td>0.499911</td>\n",
       "      <td>0.201165</td>\n",
       "      <td>0.183787</td>\n",
       "      <td>0.151217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.499916</td>\n",
       "      <td>0.479727</td>\n",
       "      <td>ST32000542AS.csv</td>\n",
       "      <td>0.499916</td>\n",
       "      <td>0.382598</td>\n",
       "      <td>0.380919</td>\n",
       "      <td>0.377590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.499922</td>\n",
       "      <td>0.482247</td>\n",
       "      <td>ST3160316AS.csv</td>\n",
       "      <td>0.499922</td>\n",
       "      <td>0.049990</td>\n",
       "      <td>0.049990</td>\n",
       "      <td>0.049990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.528457</td>\n",
       "      <td>0.479389</td>\n",
       "      <td>ST31500541AS.csv</td>\n",
       "      <td>0.528457</td>\n",
       "      <td>0.474165</td>\n",
       "      <td>0.472167</td>\n",
       "      <td>0.470363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.566657</td>\n",
       "      <td>0.479213</td>\n",
       "      <td>ST8000DM002.csv</td>\n",
       "      <td>0.566657</td>\n",
       "      <td>0.435894</td>\n",
       "      <td>0.429359</td>\n",
       "      <td>0.422831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.611081</td>\n",
       "      <td>0.479456</td>\n",
       "      <td>WDC WD60EFRX.csv</td>\n",
       "      <td>0.611081</td>\n",
       "      <td>0.464748</td>\n",
       "      <td>0.419555</td>\n",
       "      <td>0.362960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480872</td>\n",
       "      <td>WDC WD800AAJS.csv</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DecisionTreeClassifier  FakeAlgorithm          drive_csv  winner_f_beta  \\\n",
       "0                 0.499613       0.476075    ST4000DM005.csv       0.499613   \n",
       "1                 0.499845       0.480548    ST4000DM001.csv       0.499845   \n",
       "2                 0.499849       0.479243    ST3160318AS.csv       0.499849   \n",
       "3                 0.499889       0.479679   WDC WD20EFRX.csv       0.499889   \n",
       "4                 0.499895       0.478194  ST250LM004 HN.csv       0.499895   \n",
       "5                 0.499911       0.480173    ST9250315AS.csv       0.499911   \n",
       "6                 0.499916       0.479727   ST32000542AS.csv       0.499916   \n",
       "7                 0.499922       0.482247    ST3160316AS.csv       0.499922   \n",
       "8                 0.528457       0.479389   ST31500541AS.csv       0.528457   \n",
       "9                 0.566657       0.479213    ST8000DM002.csv       0.566657   \n",
       "10                0.611081       0.479456   WDC WD60EFRX.csv       0.611081   \n",
       "11                1.000000       0.480872  WDC WD800AAJS.csv       1.000000   \n",
       "\n",
       "    maximal_fbeta  mean_fbeta  minimal_fbeta  \n",
       "0        0.000000    0.000000       0.000000  \n",
       "1        0.049977    0.049977       0.049977  \n",
       "2        0.257868    0.249474       0.207874  \n",
       "3        0.149917    0.116601       0.049986  \n",
       "4        0.149615    0.074843       0.049752  \n",
       "5        0.201165    0.183787       0.151217  \n",
       "6        0.382598    0.380919       0.377590  \n",
       "7        0.049990    0.049990       0.049990  \n",
       "8        0.474165    0.472167       0.470363  \n",
       "9        0.435894    0.429359       0.422831  \n",
       "10       0.464748    0.419555       0.362960  \n",
       "11       0.000000    0.000000       0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.merge_and_show(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the random guess, that defined a fbeta score of $0.4792$ as mean, the kfold result of the grid searched `DecisionTreeClassifier` is more worse: $0.2032$. As requested by a review, I extended the kfold run to use different random states and recalculated them. The new mean is $0.202$ - in combination with the very low rate of failures, this low number seems legit. All folds with no predictions where classified as an fbeta score of $0.0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated fbeta scores seems not to reflect the actual performance of the implemented classifiers. Lets take a more deep view of each range of fbeta score. Note that I am using here the initial calculated fbeta score for `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta from 0.475 to 0.482"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided results show that for a lot of drives, the untrained `FakeAlgorithm` generates a score between 0.47 and 0.482. Only for the `ST33000651AS` the `LinearSVC` performs slightly better than the `FakeAlgorithm`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta from 0.484 to 0.497"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Range, the `GaussianNB` than performs better, again with an \"outlier\" by the `FakeAlgorithm`. It is possible that for the drive `ST2000DL003` the amount of data for this drive with 1238 is just not enough to let the algorithm, learn the patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta  0.499 to 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of different algorithms win with this fbeta score.\n",
    "\n",
    "|Algorithm|Wins|\n",
    "|-----|---|\n",
    "|AdaBoostClassifier|6|\n",
    "|RandomForestClassifier|2|\n",
    "|DecisionTreeClassifier|7|\n",
    "|GaussianNB|1|\n",
    "|SGDClassifier|1|\n",
    "|LinearSVC|1|\n",
    "\n",
    "This Range is the area of the somehow \"Tree\" based approaches, again with some outliers by `GaussianNB`, `SGDClassifier` and `LinearSVC`. All this drives outperform the random guess, they could detect some patterns inside the data, even with a low fbeta score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fbeta from 0.5 to 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next range is leading by `GaussianNB` again. Only for the `Hitachi HDS722020ALA330` the `NearestCentroid` algorithm wins. `GaussianNB` have a Delta of only 0.000607 - so it was really close compared to the  `NearestCentroid` algorithm. A rerun of this dataset could already generate a different score and a different winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta from 0.52 to 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Range is totally mixed. Each winner is only one time present. We also have `Keras` and `XGBoost` first time as winners for a drive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta from 0.55 to 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going on in the next Range upto 0.6, we find the first time the `LightGBM` lib by Microsoft that I also used in this project to compare it. Its also interisting that this algorithm could finish without waiting for hours to complete, as `ST4000DM000` was the second biggest dataset. It also have the higest amount of failures in total. A lot of algorithms did not finish on my local environment with this drive. I not used cloud providers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta from 0.6 to 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For to range upto 0.7, we first time find the \"default\" MLPClassifier. Suprisingly `Keras` did a really bad job on this drive. Its possible that my network that I created just not reflect the best Keras network at all..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FBeta to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the last range. We also have a fbeta Score of 1 for the drive `WDC WD800AAJS`. Note that this drive got a kfold fbeta score of a lower value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "## Free-Form Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": [
           "#e6194b",
           "#3cb44b",
           "#ffe119",
           "#4363d8",
           "#f58231",
           "#911eb4",
           "#46f0f0",
           "#f032e6",
           "#bcf60c",
           "#fabebe",
           "#008080",
           "#e6beff",
           "#9a6324"
          ],
          "line": {
           "color": "#000000",
           "width": 2
          }
         },
         "textfont": {
          "size": 10
         },
         "type": "bar",
         "uid": "3894140c-b118-11e8-92fc-fcaa14710b08",
         "x": [
          "AdaBoost",
          "DecisionTree",
          "Fake",
          "GaussianNB",
          "Keras",
          "LightGBM",
          "LinearSVC",
          "MLP",
          "NearestCentroid",
          "RandomForest",
          "SGD",
          "SVC",
          "XGBoostGbtree"
         ],
         "y": [
          12,
          12,
          9,
          10,
          4,
          2,
          3,
          1,
          1,
          4,
          1,
          0,
          1
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 400,
        "title": "Total Algorithm winners",
        "width": 600,
        "xaxis": {
         "tickangle": -45
        }
       }
      },
      "text/html": [
       "<div id=\"7a340628-b31f-4d61-99a2-0656f94c12b9\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7a340628-b31f-4d61-99a2-0656f94c12b9\", [{\"marker\": {\"color\": [\"#e6194b\", \"#3cb44b\", \"#ffe119\", \"#4363d8\", \"#f58231\", \"#911eb4\", \"#46f0f0\", \"#f032e6\", \"#bcf60c\", \"#fabebe\", \"#008080\", \"#e6beff\", \"#9a6324\"], \"line\": {\"color\": \"#000000\", \"width\": 2}}, \"textfont\": {\"size\": 10}, \"x\": [\"AdaBoost\", \"DecisionTree\", \"Fake\", \"GaussianNB\", \"Keras\", \"LightGBM\", \"LinearSVC\", \"MLP\", \"NearestCentroid\", \"RandomForest\", \"SGD\", \"SVC\", \"XGBoostGbtree\"], \"y\": [12, 12, 9, 10, 4, 2, 3, 1, 1, 4, 1, 0, 1], \"type\": \"bar\", \"uid\": \"3897bb58-b118-11e8-88dc-fcaa14710b08\"}], {\"autosize\": false, \"height\": 400, \"title\": \"Total Algorithm winners\", \"width\": 600, \"xaxis\": {\"tickangle\": -45}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7a340628-b31f-4d61-99a2-0656f94c12b9\" style=\"height: 400px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7a340628-b31f-4d61-99a2-0656f94c12b9\", [{\"marker\": {\"color\": [\"#e6194b\", \"#3cb44b\", \"#ffe119\", \"#4363d8\", \"#f58231\", \"#911eb4\", \"#46f0f0\", \"#f032e6\", \"#bcf60c\", \"#fabebe\", \"#008080\", \"#e6beff\", \"#9a6324\"], \"line\": {\"color\": \"#000000\", \"width\": 2}}, \"textfont\": {\"size\": 10}, \"x\": [\"AdaBoost\", \"DecisionTree\", \"Fake\", \"GaussianNB\", \"Keras\", \"LightGBM\", \"LinearSVC\", \"MLP\", \"NearestCentroid\", \"RandomForest\", \"SGD\", \"SVC\", \"XGBoostGbtree\"], \"y\": [12, 12, 9, 10, 4, 2, 3, 1, 1, 4, 1, 0, 1], \"type\": \"bar\", \"uid\": \"3897bb58-b118-11e8-88dc-fcaa14710b08\"}], {\"autosize\": false, \"height\": 400, \"title\": \"Total Algorithm winners\", \"width\": 600, \"xaxis\": {\"tickangle\": -45}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freestyle = Freestyle()\n",
    "freestyle.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AdaBoostClassifier` and `DecisionTreeClassifier` both share the first place in this competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps that where done for this project:\n",
    "* Download the data from backblaze\n",
    "* Unpack is, restructure the unpacked data\n",
    "* Extract each drive information to a separate file (splitting)\n",
    "* remove unneded data and reduce memory requirement for reading (minify)\n",
    "* create a train, test and validation set out of the separated files\n",
    "* Run different binary classification algorithms on the drives and compare the results with each other.\n",
    "* Do a Grid search for the winning algorithm. I did that for the `DecisionTreeClassifier`.\n",
    "* Run KFold on the improved algorithm\n",
    "* Group each drive by an fbeta score range and discuss the results\n",
    "\n",
    "Regarding this project, they where a lot of trouble. First transferring the data from the mixed form into a standard form that every possible S.M.A.R.T. value is present. Then merging this different \"raw\" files together. Then splitting each model type out of mixes and splitting again for test, train and validation set. After doing a lot of the work, I got a lot more out of memory errors than now. I had to add the drive_minify method, to reduce the total amount of data I pass to the algorithm. Before this refactoring, I loaded the entire csv file into RAM and than dropped the unneded columns - but before I could drop them, the RAM was already full and I could not continue. Calculating the size of test train and validation set was also at some point wrong, as calculating $3 \\cdot 0.1 = 0.3 -> 0 %$. But with no failures in test and validation set, the algorithms throw errors that a calculation is not possible. Having a very low amount of failures, I split the data in \"bigger\" parts to have more drives to run algorithms against.\n",
    "\n",
    "I also struggeled with not running the algorithms in sequence, as the IO operations by pandas `read_csv` not even scratch the performance of the installed SSD (A Samsung SSD 850 EVO 1 TB) - I learned a lot!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having more cpu power and RAM allows to calculate more algorithms and generate more results. Also a Gridsearch and a KFold can be implemented for more algorithms to check if it is really performing as good / poor as expeted. It is also interesting  to run them on even more frameworks like Apache Spark or pytorch to have a even bigger set of algorithms. Some cloud providers also offer their own implementation of different algorithms with hyperparameter tuning. This could also increase the number of algorithms that are comparing against each other.\n",
    "\n",
    "In general, this challange is taff, as the overall failure rate is only 1.8% of all drives in average. It is like searching a needle in a haystack (german: \"Nadel im Heuhaufen suchen\"). This is also reflected by the general low fbeta score for a lot of drives.\n",
    "\n",
    "I mixed drives with different capacity together. I could be interisting if splitting them by capacity somehow increases the accuracy. Also somebody could try to run the algorithms against all drives by a given manufacturer to have more failing drives in the datasets and compare them with my solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel like giving me feedback, write me on Twitter @dariusmurawski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
